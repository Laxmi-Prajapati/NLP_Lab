{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Bk992swhq76"
   },
   "source": [
    "# Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gC2DwW1-hg9N"
   },
   "outputs": [],
   "source": [
    "!pip install -q \\\n",
    "    nltk==3.9.1 \\\n",
    "    contractions==0.1.73 \\\n",
    "    spacy==3.8.11 \\\n",
    "    gensim==4.4.0 \\\n",
    "    fastcoref==2.1.6 \\\n",
    "    matplotlib==3.10.0 \\\n",
    "    numpy==2.0.2 \\\n",
    "    pandas==2.2.2\n",
    "\n",
    "# Install spaCy English model\n",
    "!pip install -q \"https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9h2GS8q_iiRF"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "B3If78f7rtna"
   },
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"We've got a cleaning task, isn't it?\",\n",
    "    \"He's running faster than he ever did!\",\n",
    "    \"Don't forget to bring your notebook.\",\n",
    "    \"I'm going to the market because it's urgent.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kVpZrIkpnh-U",
    "outputId": "910620f5-aac5-4fbc-c101-025bec845a5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "nltk.download(\"averaged_perceptron_tagger_eng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "maL3FZNio-fL"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import contractions\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9j_iCxWapJlv"
   },
   "outputs": [],
   "source": [
    "# Contraction Expansion\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "m0qdCbeXpNpM"
   },
   "outputs": [],
   "source": [
    "# Cleaning Function (lowercase + punctuation removal)\n",
    "def clean_text(text):\n",
    "    text = expand_contractions(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)  # remove punctuation\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BGA2ZOAbpVoY"
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eTA96N3vpbJV"
   },
   "outputs": [],
   "source": [
    "# Stopword Removal\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [token for token in tokens if token not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rECV2e4MphfL"
   },
   "outputs": [],
   "source": [
    "# POS Tagging\n",
    "def pos_tag_tokens(tokens):\n",
    "    return pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "OYw1tizwpl2s"
   },
   "outputs": [],
   "source": [
    "# WordNet POS Mapper\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return 'a'   # adjective\n",
    "    elif tag.startswith('V'):\n",
    "        return 'v'   # verb\n",
    "    elif tag.startswith('N'):\n",
    "        return 'n'   # noun\n",
    "    elif tag.startswith('R'):\n",
    "        return 'r'   # adverb\n",
    "    return 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bxx_jv_NpqHy"
   },
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_tokens(tagged_tokens):\n",
    "    lemmatized = [\n",
    "        lemmatizer.lemmatize(word, get_wordnet_pos(pos))\n",
    "        for word, pos in tagged_tokens\n",
    "    ]\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iGgRNYiJpxWD",
    "outputId": "e3e9f725-9df8-49ab-e605-9576f45afb80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Sentence 1 ======\n",
      "Original: We've got a cleaning task, isn't it?\n",
      "Cleaned: we have got a cleaning task is not it\n",
      "Tokens: ['we', 'have', 'got', 'a', 'cleaning', 'task', 'is', 'not', 'it']\n",
      "Tokens (no stopwords): ['got', 'cleaning', 'task']\n",
      "POS Tagged: [('got', 'VBD'), ('cleaning', 'VBG'), ('task', 'NN')]\n",
      "Lemmatized: ['get', 'clean', 'task']\n",
      "\n",
      "====== Sentence 2 ======\n",
      "Original: He's running faster than he ever did!\n",
      "Cleaned: he is running faster than he ever did\n",
      "Tokens: ['he', 'is', 'running', 'faster', 'than', 'he', 'ever', 'did']\n",
      "Tokens (no stopwords): ['running', 'faster', 'ever']\n",
      "POS Tagged: [('running', 'VBG'), ('faster', 'RBR'), ('ever', 'RB')]\n",
      "Lemmatized: ['run', 'faster', 'ever']\n",
      "\n",
      "====== Sentence 3 ======\n",
      "Original: Don't forget to bring your notebook.\n",
      "Cleaned: do not forget to bring your notebook\n",
      "Tokens: ['do', 'not', 'forget', 'to', 'bring', 'your', 'notebook']\n",
      "Tokens (no stopwords): ['forget', 'bring', 'notebook']\n",
      "POS Tagged: [('forget', 'VB'), ('bring', 'NN'), ('notebook', 'NN')]\n",
      "Lemmatized: ['forget', 'bring', 'notebook']\n",
      "\n",
      "====== Sentence 4 ======\n",
      "Original: I'm going to the market because it's urgent.\n",
      "Cleaned: i am going to the market because it is urgent\n",
      "Tokens: ['i', 'am', 'going', 'to', 'the', 'market', 'because', 'it', 'is', 'urgent']\n",
      "Tokens (no stopwords): ['going', 'market', 'urgent']\n",
      "POS Tagged: [('going', 'VBG'), ('market', 'NN'), ('urgent', 'NN')]\n",
      "Lemmatized: ['go', 'market', 'urgent']\n"
     ]
    }
   ],
   "source": [
    "# Full Pipeline Execution\n",
    "for i, sentence in enumerate(corpus, start=1):\n",
    "    print(f\"\\n====== Sentence {i} ======\")\n",
    "\n",
    "    cleaned = clean_text(sentence)\n",
    "    tokens = tokenize(cleaned)\n",
    "    tokens_no_sw = remove_stopwords(tokens)\n",
    "    tagged = pos_tag_tokens(tokens_no_sw)\n",
    "    lemmatized = lemmatize_tokens(tagged)\n",
    "\n",
    "    print(\"Original:\", sentence)\n",
    "    print(\"Cleaned:\", cleaned)\n",
    "    print(\"Tokens:\", tokens)\n",
    "    print(\"Tokens (no stopwords):\", tokens_no_sw)\n",
    "    print(\"POS Tagged:\", tagged)\n",
    "    print(\"Lemmatized:\", lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVj7GY_ZrjjU"
   },
   "source": [
    "# POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZ3DBLOFuCbP"
   },
   "source": [
    "Rule Based POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vuWma0zurnr3"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SMPcpHgCt7jt"
   },
   "outputs": [],
   "source": [
    "def pos_tag_rule_based(text):\n",
    "    \"\"\"\n",
    "    Rule-based POS tagging using NLTK's built-in tagger.\n",
    "    Removes stopwords before tagging.\n",
    "    Returns a list of lists: [ [(word, tag), ...], ... ]\n",
    "    \"\"\"\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    tagged_output = []\n",
    "\n",
    "    for sent in sentences:\n",
    "        words = word_tokenize(sent)\n",
    "        words = [w for w in words if w.lower() not in stop_words]  # remove stopwords\n",
    "        tagged = nltk.pos_tag(words)\n",
    "        tagged_output.append(tagged)\n",
    "\n",
    "    return tagged_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H_Zn05eHuKs7",
    "outputId": "5d8affd7-d641-43e4-ac9f-41a28bca1e30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('dog', 'NN'), ('sat', 'VBD'), ('mat', 'NN'), ('barked', 'VBD'), ('loudly', 'RB'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# Rule-based tagging\n",
    "text = \"The dog sat on the mat and it barked loudly.\"\n",
    "\n",
    "pos_tagged = pos_tag_rule_based(text)\n",
    "print(pos_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MWTBa39UuWT5"
   },
   "source": [
    "HMM based POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NXxz274jubme"
   },
   "outputs": [],
   "source": [
    "def train_hmm_pos_tagger(train_data):\n",
    "    \"\"\"\n",
    "    Trains a simple HMM POS tagger using:\n",
    "    - transition probabilities\n",
    "    - emission probabilities\n",
    "    - start probabilities\n",
    "    Returns a model dictionary.\n",
    "    \"\"\"\n",
    "    transition = defaultdict(lambda: defaultdict(int))\n",
    "    emission = defaultdict(lambda: defaultdict(int))\n",
    "    start_prob = defaultdict(int)\n",
    "    tag_counts = defaultdict(int)\n",
    "\n",
    "    # Count frequencies\n",
    "    for sentence in train_data:\n",
    "        prev_tag = None\n",
    "        for i, (word, tag) in enumerate(sentence):\n",
    "\n",
    "            tag_counts[tag] += 1\n",
    "            emission[tag][word] += 1\n",
    "\n",
    "            if i == 0:\n",
    "                start_prob[tag] += 1\n",
    "            else:\n",
    "                transition[prev_tag][tag] += 1\n",
    "\n",
    "            prev_tag = tag\n",
    "\n",
    "    # Normalize helper\n",
    "    def normalize(d):\n",
    "        total = sum(d.values())\n",
    "        return {k: v / total for k, v in d.items()}\n",
    "\n",
    "    # Normalize all distributions\n",
    "    start_prob = normalize(start_prob)\n",
    "    for tag in emission:\n",
    "        emission[tag] = normalize(emission[tag])\n",
    "    for prev in transition:\n",
    "        transition[prev] = normalize(transition[prev])\n",
    "\n",
    "    states = list(tag_counts.keys())\n",
    "\n",
    "    return {\n",
    "        \"states\": states,\n",
    "        \"start_prob\": start_prob,\n",
    "        \"transition\": transition,\n",
    "        \"emission\": emission\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "5XBw1p-FulYC"
   },
   "outputs": [],
   "source": [
    "def viterbi(sentence, states, start_p, trans_p, emit_p):\n",
    "    \"\"\"\n",
    "    The Viterbi algorithm finds the most probable sequence of POS tags for a given sentence\n",
    "    using dynamic programming. It computes probabilities using start, transition, and\n",
    "    emission probabilities of the HMM and selects the highest-likelihood tag path.\n",
    "    The final output is the best possible tag sequence for the input words.\n",
    "    \"\"\"\n",
    "    V = [{}]\n",
    "    path = {}\n",
    "\n",
    "    # Initial state\n",
    "    for state in states:\n",
    "        V[0][state] = start_p.get(state, 0) * emit_p[state].get(sentence[0], 1e-6)\n",
    "        path[state] = [state]\n",
    "\n",
    "    # Recursion\n",
    "    for t in range(1, len(sentence)):\n",
    "        V.append({})\n",
    "        new_path = {}\n",
    "\n",
    "        for curr_state in states:\n",
    "            max_prob, prev_state = max(\n",
    "                (\n",
    "                    V[t-1][y0]\n",
    "                    * trans_p[y0].get(curr_state, 1e-6)\n",
    "                    * emit_p[curr_state].get(sentence[t], 1e-6),\n",
    "                    y0\n",
    "                )\n",
    "                for y0 in states\n",
    "            )\n",
    "\n",
    "            V[t][curr_state] = max_prob\n",
    "            new_path[curr_state] = path[prev_state] + [curr_state]\n",
    "\n",
    "        path = new_path\n",
    "\n",
    "    # Termination\n",
    "    n = len(sentence) - 1\n",
    "    prob, final_state = max((V[n][y], y) for y in states)\n",
    "\n",
    "    return path[final_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "OODVhn2CutgZ"
   },
   "outputs": [],
   "source": [
    "def pos_tag_hmm(tokens, hmm_model):\n",
    "    \"\"\"\n",
    "    Performs HMM-based POS tagging on a tokenized sentence.\n",
    "    tokens → list of words\n",
    "    hmm_model → output of train_hmm_pos_tagger()\n",
    "    \"\"\"\n",
    "    states = hmm_model[\"states\"]\n",
    "    start_prob = hmm_model[\"start_prob\"]\n",
    "    transition = hmm_model[\"transition\"]\n",
    "    emission = hmm_model[\"emission\"]\n",
    "\n",
    "    predicted_tags = viterbi(tokens, states, start_prob, transition, emission)\n",
    "\n",
    "    return list(zip(tokens, predicted_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BlHeVuGUusdh",
    "outputId": "dbca550f-09a5-43b8-835e-d152784de38c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 'DET'), ('cat', 'NOUN'), ('barked', 'VERB')]\n"
     ]
    }
   ],
   "source": [
    "# HMM training data\n",
    "train_data = [\n",
    "    [(\"the\", \"DET\"), (\"cat\", \"NOUN\"), (\"sat\", \"VERB\")],\n",
    "    [(\"the\", \"DET\"), (\"dog\", \"NOUN\"), (\"barked\", \"VERB\")],\n",
    "    [(\"a\", \"DET\"), (\"dog\", \"NOUN\"), (\"sat\", \"VERB\")],\n",
    "]\n",
    "\n",
    "# Train HMM\n",
    "hmm_model = train_hmm_pos_tagger(train_data)\n",
    "\n",
    "# Test sentence\n",
    "sentence = [\"a\", \"cat\", \"barked\"]\n",
    "pos_tagged = pos_tag_hmm(sentence, hmm_model)\n",
    "print(pos_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJDCTY83vxjE"
   },
   "source": [
    "# N-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ERXUItowViM",
    "outputId": "6a1f3857-6774-4fde-daa9-45f7d85b151c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download required NLTK data\n",
    "nltk.download('reuters')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ZzZn7pzhw0Yy"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKQ5_YSev2ES"
   },
   "source": [
    "Bi-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "TkqHkR7Uv5Sj"
   },
   "outputs": [],
   "source": [
    "from nltk import bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "zauQS27Pv8h7"
   },
   "outputs": [],
   "source": [
    "def clean_and_merge(text):\n",
    "    text = re.sub(r'\\bU\\.S\\.\\b', 'US', text)\n",
    "    text = re.sub(r'\\bU\\.N\\.\\b', 'UN', text)\n",
    "    text = re.sub(r'\\bU\\.K\\.\\b', 'UK', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Hh2PWHWCv_Dy"
   },
   "outputs": [],
   "source": [
    "def build_bigram_model():\n",
    "    \"\"\"\n",
    "    This function builds a Bigram model by counting adjacent word pairs\n",
    "    (w1, w2) from the Reuters corpus and converting the raw counts into\n",
    "    conditional probabilities. It also merges abbreviations like U.S./U.N.\n",
    "    and tokenizes each document individually for accuracy.\n",
    "    \"\"\"\n",
    "    model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "    for file_id in reuters.fileids():\n",
    "        text = reuters.raw(file_id)\n",
    "        text = clean_and_merge(text)\n",
    "        words = nltk.word_tokenize(text)\n",
    "\n",
    "        for w1, w2 in bigrams(words):\n",
    "            model[w1][w2] += 1\n",
    "\n",
    "    # normalize\n",
    "    for w1 in model:\n",
    "        total = float(sum(model[w1].values()))\n",
    "        for w2 in model[w1]:\n",
    "            model[w1][w2] /= total\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "9ONkMrDHwF5J"
   },
   "outputs": [],
   "source": [
    "def predict_next_word_bigram(w1, model):\n",
    "    \"\"\"\n",
    "    This function predicts the next word given a single previous word using\n",
    "    the trained Bigram probability distribution. It selects the word with\n",
    "    the highest conditional probability P(w2 | w1). If no match exists,\n",
    "    a fallback message is returned.\n",
    "    \"\"\"\n",
    "    next_word_probs = model[w1]\n",
    "\n",
    "    if next_word_probs:\n",
    "        return max(next_word_probs, key=next_word_probs.get)\n",
    "    else:\n",
    "        return \"No prediction available\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RIAlObqEwbXG",
    "outputId": "9c5fc2e3-8f60-47b1-9ac9-39288931d500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Next Word: company\n"
     ]
    }
   ],
   "source": [
    "bigram_model = build_bigram_model()\n",
    "print(\"Bigram Next Word:\", predict_next_word_bigram(\"the\", bigram_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPrNACt9wpiC"
   },
   "source": [
    "Tri-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "95tpnJsTwwhc"
   },
   "outputs": [],
   "source": [
    "from nltk import trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "kSb_kps4wl5K"
   },
   "outputs": [],
   "source": [
    "def build_trigram_model():\n",
    "    \"\"\"\n",
    "    This function builds a Trigram language model by counting occurrences\n",
    "    of word triples (w1, w2, w3) across the Reuters corpus. It then converts\n",
    "    these counts into conditional probabilities P(w3 | w1, w2). This captures\n",
    "    stronger contextual relationships than bigrams.\n",
    "    \"\"\"\n",
    "    model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "    words = nltk.word_tokenize(' '.join(reuters.words()))\n",
    "    tri_grams = list(trigrams(words))\n",
    "\n",
    "    # count occurrences\n",
    "    for w1, w2, w3 in tri_grams:\n",
    "        model[(w1, w2)][w3] += 1\n",
    "\n",
    "    # normalize\n",
    "    for w1_w2 in model:\n",
    "        total = float(sum(model[w1_w2].values()))\n",
    "        for w3 in model[w1_w2]:\n",
    "            model[w1_w2][w3] /= total\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Sgi17pkTw7WT"
   },
   "outputs": [],
   "source": [
    "def predict_next_word_trigram(w1, w2, model):\n",
    "    \"\"\"\n",
    "    This function predicts the next word using the previous two words as\n",
    "    context. It chooses the word with the highest probability from the\n",
    "    Trigram distribution P(w3 | w1, w2). If the word pair is unseen,\n",
    "    it returns a fallback message.\n",
    "    \"\"\"\n",
    "    next_word_probs = model[(w1, w2)]\n",
    "\n",
    "    if next_word_probs:\n",
    "        return max(next_word_probs, key=next_word_probs.get)\n",
    "    else:\n",
    "        return \"No prediction available\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgFE9XY-wc4W",
    "outputId": "96f8fff1-1455-479e-f293-95793693d65f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram Next Word: of\n"
     ]
    }
   ],
   "source": [
    "trigram_model = build_trigram_model()\n",
    "print(\"Trigram Next Word:\", predict_next_word_trigram(\"the\", \"stock\", trigram_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4GpofTfxXFZ"
   },
   "source": [
    "# Parse Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2gLBT4D8xZUE",
    "outputId": "49203b6d-ef94-49fb-d410-c2472e48bc86"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize, RegexpParser\n",
    "from nltk.tree import Tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "hT5dZZFWxrgV"
   },
   "outputs": [],
   "source": [
    "def generate_parse_tree(text):\n",
    "    \"\"\"\n",
    "    This function takes a raw sentence, tokenizes it, performs POS tagging,\n",
    "    and applies a chunk grammar to generate a parse tree. It identifies key\n",
    "    linguistic structures such as NP, VP, and PP to create syntactic chunks.\n",
    "    The final output is an NLTK Tree object.\n",
    "    \"\"\"\n",
    "    # Step 1: Tokenize + POS Tag\n",
    "    tagged = pos_tag(word_tokenize(text))\n",
    "\n",
    "    # Step 2: Grammar Rules\n",
    "    grammar = r\"\"\"\n",
    "        NP: {<DT>?<JJ>*<NN>}    # Noun Phrase\n",
    "        P: {<IN>}               # Preposition\n",
    "        V: {<V.*>}              # Verb\n",
    "        PP: {<P> <NP>}          # Prepositional Phrase\n",
    "        VP: {<V> <NP|PP>*}      # Verb Phrase\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 3: Parse\n",
    "    chunker = RegexpParser(grammar)\n",
    "    tree = chunker.parse(tagged)\n",
    "\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Ib7PGwnMxynq"
   },
   "outputs": [],
   "source": [
    "def draw_tree(tree):\n",
    "    \"\"\"Recursively draw NLTK parse tree using matplotlib.\n",
    "    This function visualizes an NLTK parse tree using matplotlib. It recursively\n",
    "    draws each node and its children, producing a clean hierarchical syntactic\n",
    "    tree. It is useful for observing grammatical structure in a non-GUI\n",
    "    environment like Google Colab.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n--- Matplotlib Visual Tree Representation ---\\n\")\n",
    "\n",
    "    def _draw(tree, x, y, dx):\n",
    "        label = tree.label() if isinstance(tree, Tree) else str(tree)\n",
    "        plt.text(x, y, label,\n",
    "                 ha='center', fontsize=10,\n",
    "                 bbox=dict(facecolor='white',\n",
    "                           edgecolor='black',\n",
    "                           boxstyle='round,pad=0.3'))\n",
    "        if isinstance(tree, Tree):\n",
    "            n_children = len(tree)\n",
    "            if n_children > 0:\n",
    "                step = dx / n_children\n",
    "                for i, child in enumerate(tree):\n",
    "                    new_x = x - dx/2 + step/2 + i*step\n",
    "                    new_y = y - 1\n",
    "                    plt.plot([x, new_x], [y - 0.1, new_y + 0.3],\n",
    "                             color='black', linewidth=0.8)\n",
    "                    _draw(child, new_x, new_y, step/1.5)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    _draw(tree, 0, 0, 10)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "aZkfAhiGx-3s"
   },
   "outputs": [],
   "source": [
    "def print_tree_views(tree):\n",
    "    \"\"\"\n",
    "    This function prints two readable forms of the parse tree: a structured\n",
    "    text representation and an ASCII pretty-printed layout. It helps analyze\n",
    "    syntactic chunks directly in the console without graphics.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Text Tree Representation ---\\n\")\n",
    "    print(tree.pformat())\n",
    "\n",
    "    print(\"\\n\" + \"-\"*90)\n",
    "    print(\"\\n--- ASCII Tree (console view) ---\\n\")\n",
    "    tree.pretty_print()\n",
    "    print(\"\\n\" + \"-\"*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "E8H7mhtayFy2"
   },
   "outputs": [],
   "source": [
    "def parse_pipeline(text):\n",
    "    \"\"\"\n",
    "    A full pipeline that generates the parse tree, prints text and ASCII\n",
    "    visualizations, and displays the matplotlib version. This combines\n",
    "    all parsing steps into a single convenient function.\n",
    "    \"\"\"\n",
    "    tree = generate_parse_tree(text)\n",
    "    print_tree_views(tree)\n",
    "    draw_tree(tree)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 985
    },
    "id": "LvoTQXWcyLfO",
    "outputId": "066bac2c-ba80-4a47-9465-e1fc3d3b76f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Text Tree Representation ---\n",
      "\n",
      "(S\n",
      "  (NP The/DT quick/JJ brown/NN)\n",
      "  (NP fox/NN)\n",
      "  (VP (V jumps/VBZ) (PP (P over/IN) (NP the/DT lazy/JJ dog/NN))))\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "--- ASCII Tree (console view) ---\n",
      "\n",
      "                                    S                                      \n",
      "           _________________________|_______________                        \n",
      "          |                |                        VP                     \n",
      "          |                |         _______________|_____                  \n",
      "          |                |        |                     PP               \n",
      "          |                |        |         ____________|_____            \n",
      "          NP               NP       V        P                  NP         \n",
      "   _______|________        |        |        |       ___________|______     \n",
      "The/DT quick/JJ brown/NN fox/NN jumps/VBZ over/IN the/DT     lazy/JJ dog/NN\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "--- Matplotlib Visual Tree Representation ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = \"The quick brown fox jumps over the lazy dog\"\n",
    "tree = parse_pipeline(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZWKSBiyqKZI"
   },
   "source": [
    "# Morphological Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "TKg2s1QO06Jy"
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"I am reading a fascinating book.\",\n",
    "    \"She walks to school every morning.\",\n",
    "    \"They played football yesterday.\",\n",
    "    \"The dog is sleeping under the table.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "qq02xrkY1BdI"
   },
   "outputs": [],
   "source": [
    "# Morphological Parsing Functions\n",
    "import spacy\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "7TzHGeVeroXI"
   },
   "outputs": [],
   "source": [
    "# Load spaCy model safely\n",
    "def load_spacy_model():\n",
    "    try:\n",
    "        return spacy.load(\"en_core_web_sm\")\n",
    "    except OSError:\n",
    "        print(\"Downloading 'en_core_web_sm' model...\")\n",
    "        import os\n",
    "        os.system(\"python -m spacy download en_core_web_sm\")\n",
    "        return spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "2AxEB9GH0P3g"
   },
   "outputs": [],
   "source": [
    "def morph_tokenize(nlp, text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    This function tokenizes English text using spaCy’s built-in tokenizer.\n",
    "    It returns a clean list of token strings. Useful as the first step of\n",
    "    morphological and syntactic analysis.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Yoky1P0E0WWu"
   },
   "outputs": [],
   "source": [
    "def analyze_token(token) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    This function extracts POS tags, lemmas, suffixes, and full morphological\n",
    "    features for a single token. It mirrors Polyglot-style detailed morphology.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"word\": token.text,\n",
    "        \"pos\": token.pos_,\n",
    "        \"stem\": token.lemma_,\n",
    "        \"suffix\": token.text[len(token.lemma_):]\n",
    "                  if token.text.lower().startswith(token.lemma_.lower()) else \"\",\n",
    "        \"features\": str(token.morph) if token.morph else \"-\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "PknQrGsj0cr6"
   },
   "outputs": [],
   "source": [
    "def parse_morphology(nlp, text: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    This function processes an entire sentence and returns complete morphological\n",
    "    information for each token. It applies tokenization, POS tagging, lemmatization,\n",
    "    and feature extraction in one unified step.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    return [analyze_token(token) for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "eJevj1n30jZk"
   },
   "outputs": [],
   "source": [
    "def print_morphology_table(analyses: List[Dict[str, str]]):\n",
    "    \"\"\"\n",
    "    Prints morphological results in a clean tabular format.\n",
    "    Useful for readability during NLP preprocessing, debugging,\n",
    "    or linguistic analysis.\n",
    "    \"\"\"\n",
    "    print(f\"{'Word':<15} {'POS':<8} {'Stem':<15} {'Suffix':<10} {'Features':<50}\")\n",
    "    print(\"-\" * 120)\n",
    "    for a in analyses:\n",
    "        print(f\"{a['word']:<15} {a['pos']:<8} {a['stem']:<15} {a['suffix']:<10} {a['features']:<50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "5ZmMGtA90qUV"
   },
   "outputs": [],
   "source": [
    "def run_morph_pipeline(text: str):\n",
    "    \"\"\"\n",
    "    A complete morphological pipeline: loads spaCy, runs tokenization,\n",
    "    POS tagging, lemma extraction, and prints the results. Perfect for\n",
    "    integration into your broader NLP workflow.\n",
    "    \"\"\"\n",
    "    nlp = load_spacy_model()\n",
    "    print(f\"\\nInput Sentence: {text}\")\n",
    "    print(\"-\" * 120)\n",
    "\n",
    "    analyses = parse_morphology(nlp, text)\n",
    "    print_morphology_table(analyses)\n",
    "\n",
    "    return analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "wC-nKW2f0vmn"
   },
   "outputs": [],
   "source": [
    "def run_morph_pipeline(text: str):\n",
    "    \"\"\"\n",
    "    A complete morphological pipeline: loads spaCy, runs tokenization,\n",
    "    POS tagging, lemma extraction, and prints the results. Perfect for\n",
    "    integration into your broader NLP workflow.\n",
    "    \"\"\"\n",
    "    nlp = load_spacy_model()\n",
    "    print(f\"\\nInput Sentence: {text}\")\n",
    "    print(\"-\" * 120)\n",
    "\n",
    "    analyses = parse_morphology(nlp, text)\n",
    "    print_morphology_table(analyses)\n",
    "\n",
    "    return analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aTHkmIVM02VF",
    "outputId": "7791df58-7bc8-42b9-c386-4ceb2c2d29b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input Sentence: I am reading a fascinating book.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Word            POS      Stem            Suffix     Features                                          \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "I               PRON     I                          Case=Nom|Number=Sing|Person=1|PronType=Prs        \n",
      "am              AUX      be                         Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin\n",
      "reading         VERB     read            ing        Aspect=Prog|Tense=Pres|VerbForm=Part              \n",
      "a               DET      a                          Definite=Ind|PronType=Art                         \n",
      "fascinating     ADJ      fascinating                Degree=Pos                                        \n",
      "book            NOUN     book                       Number=Sing                                       \n",
      ".               PUNCT    .                          PunctType=Peri                                    \n",
      "\n",
      "Input Sentence: She walks to school every morning.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Word            POS      Stem            Suffix     Features                                          \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "She             PRON     she                        Case=Nom|Gender=Fem|Number=Sing|Person=3|PronType=Prs\n",
      "walks           VERB     walk            s          Number=Sing|Person=3|Tense=Pres|VerbForm=Fin      \n",
      "to              ADP      to                         -                                                 \n",
      "school          NOUN     school                     Number=Sing                                       \n",
      "every           DET      every                      -                                                 \n",
      "morning         NOUN     morning                    Number=Sing                                       \n",
      ".               PUNCT    .                          PunctType=Peri                                    \n",
      "\n",
      "Input Sentence: They played football yesterday.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Word            POS      Stem            Suffix     Features                                          \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "They            PRON     they                       Case=Nom|Number=Plur|Person=3|PronType=Prs        \n",
      "played          VERB     play            ed         Tense=Past|VerbForm=Fin                           \n",
      "football        NOUN     football                   Number=Sing                                       \n",
      "yesterday       NOUN     yesterday                  Number=Sing                                       \n",
      ".               PUNCT    .                          PunctType=Peri                                    \n",
      "\n",
      "Input Sentence: The dog is sleeping under the table.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Word            POS      Stem            Suffix     Features                                          \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "The             DET      the                        Definite=Def|PronType=Art                         \n",
      "dog             NOUN     dog                        Number=Sing                                       \n",
      "is              AUX      be                         Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "sleeping        VERB     sleep           ing        Aspect=Prog|Tense=Pres|VerbForm=Part              \n",
      "under           ADP      under                      -                                                 \n",
      "the             DET      the                        Definite=Def|PronType=Art                         \n",
      "table           NOUN     table                      Number=Sing                                       \n",
      ".               PUNCT    .                          PunctType=Peri                                    \n"
     ]
    }
   ],
   "source": [
    "nlp = load_spacy_model()\n",
    "\n",
    "for s in sentences:\n",
    "    run_morph_pipeline(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6QZ4mgP1J6Y"
   },
   "source": [
    "# Word Sense Disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "aXMlOPT21xhr"
   },
   "outputs": [],
   "source": [
    "X = \"The die is cast.\"\n",
    "Y = \"Roll the die to get a 6.\"\n",
    "Z = \"What is dead may never die.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wd_C3qVF15zO"
   },
   "source": [
    "Lesk Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tfKyzdry2Fzu",
    "outputId": "eab3eef1-717c-4a1c-92f6-fcec4c84e410"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import wsd\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# Download required resources\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "Iq8sQUrB1pGm"
   },
   "outputs": [],
   "source": [
    "def apply_lesk(sentence: str, target_word: str, pos=None):\n",
    "    \"\"\"\n",
    "    Apply the standard Lesk algorithm for Word Sense Disambiguation.\n",
    "    Returns the best-fitting WordNet synset for the target word.\n",
    "    \"\"\"\n",
    "    tokens = sentence.split()\n",
    "    return wsd.lesk(tokens, target_word, pos=pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CbLnnH2L1s4B",
    "outputId": "9462bc1f-d29a-404e-d24a-99f8fa4de1a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- LESK RESULTS ----\n",
      "Sentence: The die is cast.\n",
      "Sense: Synset('die.v.07')\n",
      "Definition: cut or shape with a die \n",
      "\n",
      "Sentence: Roll the die to get a 6.\n",
      "Sense: Synset('die.v.08')\n",
      "Definition: to be on base at the end of an inning, of a player \n",
      "\n",
      "Sentence: What is dead may never die.\n",
      "Sense: Synset('fail.v.04')\n",
      "Definition: stop operating or functioning\n"
     ]
    }
   ],
   "source": [
    "# Test sentences\n",
    "\n",
    "print(\"---- LESK RESULTS ----\")\n",
    "\n",
    "sense = apply_lesk(X, \"die\")\n",
    "print(\"Sentence:\", X)\n",
    "print(\"Sense:\", sense)\n",
    "print(\"Definition:\", sense.definition(), \"\\n\")\n",
    "\n",
    "sense = apply_lesk(Y, \"die\")\n",
    "print(\"Sentence:\", Y)\n",
    "print(\"Sense:\", sense)\n",
    "print(\"Definition:\", sense.definition(), \"\\n\")\n",
    "\n",
    "sense = apply_lesk(Z, \"die\", pos=wn.VERB)\n",
    "print(\"Sentence:\", Z)\n",
    "print(\"Sense:\", sense)\n",
    "print(\"Definition:\", sense.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqBa9hij19L-"
   },
   "source": [
    "Adapted Lesk Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZAWU62413gx",
    "outputId": "2c2a209c-bbfd-4782-9d88-33632b7bb004"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "foRa71A52LAp"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def tokenize_and_lemmatize(text):\n",
    "    return [\n",
    "        lemmatizer.lemmatize(w.lower())\n",
    "        for w in nltk.word_tokenize(text)\n",
    "        if w.isalpha() and w.lower() not in stop_words\n",
    "    ]\n",
    "\n",
    "def get_gloss_words(sense):\n",
    "    words = []\n",
    "    # Add definition + examples\n",
    "    words += tokenize_and_lemmatize(sense.definition())\n",
    "    for ex in sense.examples():\n",
    "        words += tokenize_and_lemmatize(ex)\n",
    "\n",
    "    # Add hypernyms & hyponyms info\n",
    "    for related in sense.hypernyms() + sense.hyponyms():\n",
    "        words += tokenize_and_lemmatize(related.definition())\n",
    "        for ex in related.examples():\n",
    "            words += tokenize_and_lemmatize(ex)\n",
    "\n",
    "    return set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "GjBLmu5S2VCG"
   },
   "outputs": [],
   "source": [
    "def apply_adapted_lesk(sentence: str, target_word: str, pos=None):\n",
    "    \"\"\"\n",
    "    Apply the Adapted Lesk algorithm for Word Sense Disambiguation.\n",
    "    Computes overlap between context and gloss-expanded sense definitions.\n",
    "    \"\"\"\n",
    "    context = set(tokenize_and_lemmatize(sentence))\n",
    "    best_sense = None\n",
    "    max_overlap = 0\n",
    "\n",
    "    for sense in wn.synsets(target_word, pos=pos):\n",
    "        gloss_words = get_gloss_words(sense)\n",
    "        overlap = len(context.intersection(gloss_words))\n",
    "\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            best_sense = sense\n",
    "\n",
    "    return best_sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JrwODVWB2XhV",
    "outputId": "9f7d5e72-7a8d-4cac-b8cc-855a5f5c00bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- ADAPTED LESK RESULTS ----\n",
      "Sentence: The die is cast.\n",
      "Sense: Synset('die.n.01')\n",
      "Definition: a small cube with 1 to 6 spots on the six faces; used in gambling to generate random numbers \n",
      "\n",
      "Sentence: Roll the die to get a 6.\n",
      "Sense: Synset('die.n.01')\n",
      "Definition: a small cube with 1 to 6 spots on the six faces; used in gambling to generate random numbers \n",
      "\n",
      "Sentence: What is dead may never die.\n",
      "Sense: Synset('die.v.01')\n",
      "Definition: pass from physical life and lose all bodily attributes and functions necessary to sustain life\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n---- ADAPTED LESK RESULTS ----\")\n",
    "\n",
    "sense = apply_adapted_lesk(X, \"die\", pos=wn.NOUN)\n",
    "print(\"Sentence:\", X)\n",
    "print(\"Sense:\", sense)\n",
    "print(\"Definition:\", sense.definition(), \"\\n\")\n",
    "\n",
    "sense = apply_adapted_lesk(Y, \"die\", pos=wn.NOUN)\n",
    "print(\"Sentence:\", Y)\n",
    "print(\"Sense:\", sense)\n",
    "print(\"Definition:\", sense.definition(), \"\\n\")\n",
    "\n",
    "sense = apply_adapted_lesk(Z, \"die\", pos=wn.VERB)\n",
    "print(\"Sentence:\", Z)\n",
    "print(\"Sense:\", sense)\n",
    "print(\"Definition:\", sense.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMu8SYI92emy"
   },
   "source": [
    "# Embedding Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TRavPpC2kci"
   },
   "source": [
    "Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "S2acea3R3KZm"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Aarav was an ambitious software engineer working at a bustling tech company in Mumbai.\n",
    "Every morning, he arrived early to review code and plan the day ahead.\n",
    "His colleague Meera admired Aarav’s dedication and often collaborated with him on large projects.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "7SuZsBRo2j_l"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "CxE_Fc0L29-n"
   },
   "outputs": [],
   "source": [
    "def train_word2vec(text: str, vector_size=100, window=5, min_count=1, sg=1, epochs=100):\n",
    "    \"\"\"\n",
    "    Train a Word2Vec model on input text and return:\n",
    "      - the trained model\n",
    "      - a helper function to embed sentences (averaged vectors)\n",
    "    \"\"\"\n",
    "\n",
    "    # Preprocess text into sentences\n",
    "    sentences = [simple_preprocess(line) for line in text.split('.') if line.strip()]\n",
    "\n",
    "    # Train Word2Vec\n",
    "    model = Word2Vec(\n",
    "        sentences=sentences,\n",
    "        vector_size=vector_size,\n",
    "        window=window,\n",
    "        min_count=min_count,\n",
    "        sg=sg,\n",
    "        epochs=epochs\n",
    "    )\n",
    "\n",
    "    # Sentence embedding function\n",
    "    def embed_sentence(sentence: str):\n",
    "        tokens = simple_preprocess(sentence)\n",
    "        vectors = [model.wv[w] for w in tokens if w in model.wv]\n",
    "        if not vectors:\n",
    "            return None\n",
    "        return sum(vectors) / len(vectors)\n",
    "\n",
    "    return model, embed_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZE040HG3Evp",
    "outputId": "7b06b0f3-b514-4a35-ac04-c70e05c099b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for 'ambitious':\n",
      "[ 0.00943644 -0.00695104  0.00764546  0.00165948 -0.01069203 -0.00356773\n",
      " -0.00011429 -0.00098909 -0.00169642 -0.0085418   0.00708149  0.0077012\n",
      "  0.00035241  0.00512493 -0.00066785 -0.00182216 -0.00412811  0.0006379\n",
      "  0.00364001  0.00160092  0.00757655  0.00391411  0.0069581  -0.00894605\n",
      " -0.00233989 -0.00465325  0.00422369  0.00944937 -0.00590256  0.00415945\n",
      "  0.00675479  0.00039677  0.00333761 -0.01155748  0.0086145  -0.00562959\n",
      " -0.00668924 -0.00677403 -0.00852852 -0.00480938 -0.00964268 -0.00044238\n",
      " -0.00409252 -0.00114171  0.00784671  0.00024731  0.00108129 -0.00334709\n",
      "  0.01129654  0.00157814  0.00523525  0.00850582 -0.0113562  -0.01092334\n",
      "  0.00981511  0.00269388 -0.00232535  0.00508068 -0.00404215 -0.00675053\n",
      " -0.0096641   0.00501619  0.00071201 -0.00594264 -0.00888567  0.01029134\n",
      " -0.00281594 -0.00469016 -0.00543195 -0.00088033 -0.00197714  0.0007957\n",
      "  0.00572313  0.00197647 -0.00049695  0.00338281  0.00649182 -0.0084315\n",
      " -0.00850131  0.00728561 -0.0121688  -0.00049219 -0.01001001  0.01138441\n",
      " -0.0049587  -0.00811948  0.00058602 -0.00120867  0.00971311  0.01195765\n",
      "  0.00108033  0.00279319  0.00633854 -0.00081471 -0.00349418 -0.0011766\n",
      "  0.00270607  0.00910788 -0.00275825 -0.00988057]\n",
      "\n",
      "Sentence Embedding (average vector):\n",
      "Sentence: Aarav was a dedicated engineer.\n",
      "[ 3.9200284e-04 -2.5913317e-03  3.6111344e-03  2.1758953e-03\n",
      " -1.1442010e-03 -5.4466981e-03  5.3041182e-03  8.2278876e-03\n",
      " -4.1626389e-03 -8.4731830e-03 -9.5300149e-04 -1.9252923e-03\n",
      " -5.3152195e-03  5.3385464e-03  1.1186006e-03  3.7318300e-03\n",
      "  4.5252829e-03  2.2992764e-03 -4.4191140e-04 -3.3661555e-03\n",
      " -3.2852276e-03  3.0785752e-04  7.4352026e-03 -4.9720462e-03\n",
      "  5.4814182e-03  3.7302475e-03 -3.4008876e-03 -6.7275483e-05\n",
      " -5.5791908e-03  8.4297275e-03  5.2851518e-03 -4.6479576e-03\n",
      "  4.3721306e-03 -1.1107036e-02 -3.2543705e-03  4.5269052e-03\n",
      " -3.2444997e-03 -7.6898061e-05  4.7509154e-04  7.4924575e-04\n",
      " -1.1012187e-03 -4.1216123e-03 -4.6475548e-03  5.2238791e-03\n",
      "  6.2696370e-03 -1.2833274e-03  3.7430574e-03 -4.0351311e-03\n",
      " -1.2061046e-03  2.0897479e-03  2.4093636e-03 -1.6877620e-03\n",
      " -3.0178546e-03 -2.0327962e-03 -2.8794976e-03  1.8102186e-03\n",
      " -2.0986458e-03  1.7528372e-03 -8.5629238e-04 -1.2342833e-03\n",
      " -4.8892028e-03 -1.7094676e-03  8.1641367e-04  3.3172956e-03\n",
      " -2.1699539e-03  8.0025280e-03 -8.5340835e-05 -3.0231578e-03\n",
      " -1.8853555e-03  3.1806480e-03 -8.4271497e-04  2.1138829e-03\n",
      "  1.9879357e-03  4.5970827e-04  7.2714253e-03 -1.1949068e-03\n",
      " -5.6500845e-03  6.9538690e-04  1.2713686e-03  2.2907825e-03\n",
      " -8.8045170e-04 -2.2051830e-03  9.0860500e-04 -3.3461191e-03\n",
      "  2.7994567e-03 -8.9465681e-04  5.3628255e-03 -6.3712052e-03\n",
      "  2.3707778e-03 -4.5874869e-04 -6.9435296e-04 -3.0632475e-03\n",
      "  4.2294138e-03 -5.8962009e-03  8.8151899e-04  1.2472499e-03\n",
      "  2.6172779e-03 -1.3632976e-03 -1.8558344e-03  2.5557770e-04]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model, embed_sentence = train_word2vec(text)\n",
    "\n",
    "# Test word embedding\n",
    "print(\"Embedding for 'ambitious':\")\n",
    "print(model.wv['ambitious'])\n",
    "\n",
    "# Test sentence embedding\n",
    "sentence = \"Aarav was a dedicated engineer.\"\n",
    "vec = embed_sentence(sentence)\n",
    "\n",
    "print(\"\\nSentence Embedding (average vector):\")\n",
    "print(\"Sentence:\", sentence)\n",
    "print(vec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzUSnL3P2m3x"
   },
   "source": [
    "GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "XwIB2znh2pv6"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "5kVQU-Ri3Xxh"
   },
   "outputs": [],
   "source": [
    "def load_glove_and_utilities(model_name=\"glove-wiki-gigaword-100\"):\n",
    "    \"\"\"\n",
    "    Load a pretrained GloVe model and return:\n",
    "      - glove_model (gensim KeyedVectors)\n",
    "      - function: get_word_vector(word)\n",
    "      - function: most_similar(word, topn)\n",
    "      - function: similarity(word1, word2)\n",
    "      - function: sentence_embedding(sentence)\n",
    "    \"\"\"\n",
    "    print(\"Loading GloVe model... This may take a minute.\")\n",
    "    glove_model = api.load(model_name)\n",
    "    print(\"GloVe model loaded successfully!\\n\")\n",
    "\n",
    "    # ---- Utility: get word vector ----\n",
    "    def get_word_vector(word: str):\n",
    "        return glove_model[word] if word in glove_model else None\n",
    "\n",
    "    # ---- Utility: get most similar words ----\n",
    "    def get_most_similar(word: str, topn=5):\n",
    "        if word not in glove_model:\n",
    "            return None\n",
    "        return glove_model.most_similar(word, topn=topn)\n",
    "\n",
    "    # ---- Utility: compute similarity ----\n",
    "    def get_similarity(word1: str, word2: str):\n",
    "        if word1 not in glove_model or word2 not in glove_model:\n",
    "            return None\n",
    "        return glove_model.similarity(word1, word2)\n",
    "\n",
    "    # ---- Utility: sentence embedding ----\n",
    "    def sentence_embedding(sentence: str):\n",
    "        tokens = [w.lower() for w in sentence.split() if w.lower() in glove_model]\n",
    "        if not tokens:\n",
    "            return np.zeros(glove_model.vector_size)\n",
    "        vectors = np.array([glove_model[w] for w in tokens])\n",
    "        return np.mean(vectors, axis=0)\n",
    "\n",
    "    return glove_model, get_word_vector, get_most_similar, get_similarity, sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R_uP0UcX3cxm",
    "outputId": "5d303a52-7361-475c-c937-090b2906de90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe model... This may take a minute.\n",
      "GloVe model loaded successfully!\n",
      "\n",
      "Vector for 'science':\n",
      "[-0.13322   0.48858   0.18867   0.33791   0.54542  -0.69881   0.59954\n",
      " -0.40264  -0.26124   0.69962  -0.15999  -0.91523  -0.15415   0.60943\n",
      " -0.28774  -0.19603   0.69995   0.80869  -0.50221   0.46715  -0.53153\n",
      " -0.15619   0.30569  -0.67774   0.28715  -0.008962  0.65407  -0.47046\n",
      " -0.46508   0.2013   -1.3639    0.5951   -0.92377   0.24296  -0.81308\n",
      "  0.058247 -0.94609   0.41951  -0.79614  -0.012944 -1.0193   -0.084872\n",
      " -1.537    -0.46909  -0.13942  -0.25741   0.17223   0.64303  -0.29022\n",
      "  0.12509   0.53726  -0.42284   0.26365   0.46066  -0.075186 -1.8833\n",
      "  0.73096   0.3121    1.4856    0.21834  -0.038657  0.89277  -0.30721\n",
      " -0.27414   0.74099   0.28438   0.034259  0.7253    0.79931   0.86114\n",
      "  0.24113   0.68165   0.36753   0.15836  -1.2239    0.24132   0.42126\n",
      "  0.050802 -1.0145   -0.21926  -0.38704   0.92132  -0.52473  -0.4821\n",
      " -1.4684    0.70665   0.033025 -0.46778   0.4284   -0.58346   0.78539\n",
      " -0.26193   0.25134   0.55163  -0.33975   0.32304   0.021859 -1.0756\n",
      "  0.69851   0.18365 ]\n",
      "\n",
      "Most similar to 'science':\n",
      "[('sciences', 0.8073161244392395), ('physics', 0.7914698123931885), ('institute', 0.7663252353668213), ('mathematics', 0.7607672810554504), ('studies', 0.7590447664260864)]\n",
      "\n",
      "Similarity Examples:\n",
      "king vs queen: 0.7507691\n",
      "car vs bus: 0.7372708\n",
      "dog vs banana: 0.29064262\n",
      "\n",
      "Sentence: Artificial intelligence is transforming the world.\n",
      "Embedding shape: (100,)\n",
      "First 10 dims: [-0.1409768   0.0295618   0.5527398   0.086702    0.2836712  -0.18399738\n",
      " -0.3285968  -0.06767     0.01289979  0.2119544 ]\n"
     ]
    }
   ],
   "source": [
    "# Load GloVe and utilities\n",
    "glove_model, word_vec, most_sim, sim, sent_embed = load_glove_and_utilities()\n",
    "\n",
    "# --- Word Embedding ---\n",
    "print(\"Vector for 'science':\")\n",
    "print(word_vec(\"science\"))\n",
    "\n",
    "# --- Most Similar Words ---\n",
    "print(\"\\nMost similar to 'science':\")\n",
    "print(most_sim(\"science\", topn=5))\n",
    "\n",
    "# --- Word Similarity ---\n",
    "print(\"\\nSimilarity Examples:\")\n",
    "print(\"king vs queen:\", sim(\"king\", \"queen\"))\n",
    "print(\"car vs bus:\", sim(\"car\", \"bus\"))\n",
    "print(\"dog vs banana:\", sim(\"dog\", \"banana\"))\n",
    "\n",
    "# --- Sentence Embedding ---\n",
    "sentence = \"Artificial intelligence is transforming the world.\"\n",
    "embedding = sent_embed(sentence)\n",
    "\n",
    "print(\"\\nSentence:\", sentence)\n",
    "print(\"Embedding shape:\", embedding.shape)\n",
    "print(\"First 10 dims:\", embedding[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KKykGx23ltW"
   },
   "source": [
    "# Anaphora Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "6DpvNxWI3rLv"
   },
   "outputs": [],
   "source": [
    "from fastcoref import FCoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "VcR-DLnY3qmZ"
   },
   "outputs": [],
   "source": [
    "def coreference_resolution(text, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Perform coreference resolution using FastCoref.\n",
    "    Returns:\n",
    "        - original text\n",
    "        - resolved text with pronouns replaced by their referents\n",
    "        - result object (raw FastCoref output)\n",
    "    \"\"\"\n",
    "\n",
    "    model = FCoref(device=device)\n",
    "    result = model.predict([text])[0]\n",
    "\n",
    "    # --- Extract offsets for replacements ---\n",
    "    clusters = result.get_clusters()\n",
    "    char_map = result.char_map\n",
    "    resolved = text\n",
    "    replacements = []\n",
    "\n",
    "    # For each coreference cluster\n",
    "    for cluster in clusters:\n",
    "        representative = cluster[0]  # main entity (e.g., \"Alice\")\n",
    "\n",
    "        # Replace remaining mentions in the cluster with representative\n",
    "        for mention in cluster[1:]:\n",
    "            # find character span of this mention\n",
    "            for key, span in char_map.items():\n",
    "                start, end = span[1]\n",
    "                if text[start:end] == mention:\n",
    "                    replacements.append((start, end, representative))\n",
    "                    break\n",
    "\n",
    "    # Apply replacements from back to front (avoid shifting indices)\n",
    "    replacements.sort(reverse=True)\n",
    "    for start, end, representative in replacements:\n",
    "        resolved = resolved[:start] + representative + resolved[end:]\n",
    "\n",
    "    return text, resolved, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361,
     "referenced_widgets": [
      "276f62f0dc54440b817f5913e8fa387f",
      "0e23d3d829dd4282957e7b4c844ecea0",
      "6bc26509ee4041b3a34b246e7e5a0870",
      "297af4eec5ba455eb7013d80660b633f",
      "c53af478125a45ccbe3564624d470c2f",
      "a3463f5ece2f43859eec68ca1cee12ee",
      "cad6b0468ed34d8b942b138ebb84e117",
      "310bb3facf7041d2b084b659dddbb8a2",
      "af5bf4917c674800b66ba827bc7fa3e9",
      "32ea736659c54eeab9f64016a04466d4",
      "335a9932936941b18836d033bd0c5472",
      "1e3908124b5a45be92f6ff735b2c18f6",
      "e1974a13a0ae4fc8a62d7eecb87e70e2",
      "1a624581c549476090f76f0c89801537",
      "cb473ec09f204981896cd5f770e289b1",
      "f53eacd493304a9e8f410cf1f1641733",
      "cedaa036351443bcb11caff141f16735",
      "b19464d9b34b4184a73f839c5431b734",
      "0ebbae8d81ff4d75a64b54e4200a87d9",
      "22171c88f5854aeb84b4109c184006e3",
      "aecdb46d130e48ad8ad2f6c7b2935ca2",
      "fd5a8d7b869b4dbdbde00d7967ee7385"
     ]
    },
    "id": "2D_7_z_k4HlC",
    "outputId": "888dfa4d-4702-44c3-d3a7-88da5cbc23c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "276f62f0dc54440b817f5913e8fa387f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3908124b5a45be92f6ff735b2c18f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Text:\n",
      " Alice went to the park. She sat on a bench and read a book.\n",
      "\n",
      "Resolved Text:\n",
      " Alice went to the park. Alice sat on a bench and read a book.\n",
      "\n",
      "Available Attributes on Result Object:\n",
      "['char_map', 'clusters', 'coref_logit', 'get_clusters', 'get_logit', 'reverse_char_map', 'text', 'text_idx']\n"
     ]
    }
   ],
   "source": [
    "# --- Test the coreference resolver ---\n",
    "sample = \"Alice went to the park. She sat on a bench and read a book.\"\n",
    "\n",
    "original, resolved, raw = coreference_resolution(sample)\n",
    "\n",
    "print(\"\\nOriginal Text:\\n\", original)\n",
    "print(\"\\nResolved Text:\\n\", resolved)\n",
    "\n",
    "print(\"\\nAvailable Attributes on Result Object:\")\n",
    "attrs = [a for a in dir(raw) if not a.startswith(\"_\")]\n",
    "print(attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOu_762PFV6R"
   },
   "source": [
    "# Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "EXr-bFMZFcmp"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load SpaCy NER model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "yBtT37_bFbLl"
   },
   "outputs": [],
   "source": [
    "def perform_ner(text):\n",
    "    \"\"\"\n",
    "    Perform Named Entity Recognition (NER) on the given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input text.\n",
    "\n",
    "    Returns:\n",
    "        List of tuples: [(entity_text, entity_label), ...]\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ttNbkGjgFgjM",
    "outputId": "5db8c8de-48ca-40cc-8a42-15ecdcf7d710"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER Output: [('Barack Obama', 'PERSON'), ('Hawaii', 'GPE'), ('the United States', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Example ---------------- #\n",
    "sample_text = \"Barack Obama was born in Hawaii and became the President of the United States.\"\n",
    "\n",
    "ner_output = perform_ner(sample_text)\n",
    "print(\"NER Output:\", ner_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5AcdwDPFn_-"
   },
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "DFst7fNUGGar"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "frmGJvZHGEZ5"
   },
   "outputs": [],
   "source": [
    "def compute_tfidf(documents):\n",
    "    \"\"\"\n",
    "    Compute TF-IDF for a list of documents using:\n",
    "    tf = log10(count + 1)\n",
    "    idf = log10(N / df)\n",
    "\n",
    "    Args:\n",
    "        documents: list of strings\n",
    "\n",
    "    Returns:\n",
    "        dict: {doc_index: {word: tfidf_score}}\n",
    "    \"\"\"\n",
    "    # Tokenize\n",
    "    tokenized_docs = [doc.lower().split() for doc in documents]\n",
    "    N = len(tokenized_docs)\n",
    "\n",
    "    # Document frequency (df)\n",
    "    df = defaultdict(int)\n",
    "    for doc in tokenized_docs:\n",
    "        for word in set(doc):\n",
    "            df[word] += 1\n",
    "\n",
    "    # TF-IDF scores\n",
    "    tfidf = {}\n",
    "    for i, doc in enumerate(tokenized_docs):\n",
    "        word_counts = defaultdict(int)\n",
    "        for word in doc:\n",
    "            word_counts[word] += 1\n",
    "\n",
    "        tfidf[i] = {}\n",
    "        for word, count in word_counts.items():\n",
    "            tf = math.log10(count + 1)\n",
    "            idf = math.log10(N / df[word])\n",
    "            tfidf[i][word] = tf * idf\n",
    "\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "twldosQrGOp5",
    "outputId": "cf658800-0432-41e8-8a66-99d2f64cb161"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'i': 0.09061905828945654, 'love': 0.0, 'natural': 0.09061905828945654, 'language': 0.0, 'processing': 0.09061905828945654}, 1: {'language': 0.0, 'models': 0.09061905828945654, 'love': 0.0, 'data': 0.09061905828945654}}\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "docs = [\n",
    "    \"I love natural language processing\",\n",
    "    \"Language models love data\",\n",
    "]\n",
    "\n",
    "print(compute_tfidf(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ensTf6heGS0W"
   },
   "source": [
    "# Chunking (NP Chunk Extraction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "QF9F5DOjGfEU"
   },
   "outputs": [],
   "source": [
    "# Uses POS tagging + a simple chunk grammar.\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize, RegexpParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "b4TrECU3Gol5"
   },
   "outputs": [],
   "source": [
    "def extract_chunks(text):\n",
    "    \"\"\"\n",
    "    Extract Noun Phrase (NP) chunks from text.\n",
    "\n",
    "    Returns:\n",
    "        list of NP chunks\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "\n",
    "    grammar = \"NP: {<DT>?<JJ>*<NN.*>+}\"\n",
    "    parser = RegexpParser(grammar)\n",
    "\n",
    "    tree = parser.parse(pos_tags)\n",
    "\n",
    "    chunks = []\n",
    "    for subtree in tree.subtrees():\n",
    "        if subtree.label() == \"NP\":\n",
    "            chunk = \" \".join(word for word, pos in subtree.leaves())\n",
    "            chunks.append(chunk)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FlU03VcYGrym",
    "outputId": "3ee505a2-b29f-43f3-dc82-82b6c62c469d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The quick brown fox', 'the lazy dog']\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "print(extract_chunks(\"The quick brown fox jumped over the lazy dog.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p44KtGfAHBbg"
   },
   "source": [
    "# Sentence Similarity (Cosine Similarity + TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "zFHqcbRvHLkK"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "VSj__yX1HHgh"
   },
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2):\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between two sentences using TF-IDF.\n",
    "\n",
    "    Returns:\n",
    "        similarity score (0 to 1)\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([sent1, sent2])\n",
    "\n",
    "    sim = cosine_similarity(vectors[0:1], vectors[1:2])[0][0]\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nsvHtABkHPk6",
    "outputId": "b83d90fe-822a-4ca3-80f7-4737a72a2823"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: I love machine learning\n",
      "Sentence 2: Machine learning is my passion\n",
      "Sentence Similarity: 0.35630042933313816\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "s1 = \"I love machine learning\"\n",
    "s2 = \"Machine learning is my passion\"\n",
    "\n",
    "print(\"Sentence 1:\", s1)\n",
    "print(\"Sentence 2:\", s2)\n",
    "print(\"Sentence Similarity:\", sentence_similarity(s1, s2))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "8Bk992swhq76",
    "9h2GS8q_iiRF",
    "IVj7GY_ZrjjU",
    "UJDCTY83vxjE"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
